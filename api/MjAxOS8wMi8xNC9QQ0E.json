{"title":"PCA","date":"2019-02-13T16:00:00.000Z","date_formatted":{"ll":"Feb 14, 2019","L":"02/14/2019","MM-DD":"02-14"},"link":"2019/02/14/PCA","tags":["Machine Learning"],"categories":["Machine Learning"],"updated":"2020-02-09T08:38:16.000Z","content":"<h3 id=\"主成分分析\">主成分分析<a href=\"#主成分分析\" title=\"主成分分析\"></a></h3><p>PCA（Principal Component Analysis）</p>\n<h3 id=\"数据压缩\">数据压缩<a href=\"#数据压缩\" title=\"数据压缩\"></a></h3><p>数据压缩可以加快算法的运行时间，占用部分空间（但占用的空间极少），即是以空间换时间。</p>\n<blockquote>\n<p>2D-&gt;1D</p>\n</blockquote>\n<p><img src=\"https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/数据压缩1.PNG?raw=true\" class=\"φcy\" alt=\"image\"></p>\n<blockquote>\n<p>3D-&gt;2D</p>\n</blockquote>\n<p><img src=\"https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/数据压缩2.PNG?raw=true\" class=\"φcy\" alt=\"image\"></p>\n<h3 id=\"数据可视化\">数据可视化<a href=\"#数据可视化\" title=\"数据可视化\"></a></h3><h3 id=\"降维分析\">降维分析<a href=\"#降维分析\" title=\"降维分析\"></a></h3><p>找到数据中最重要的方向（方差最大的方向）</p>\n<p><img src=\"https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/数据压缩3.PNG?raw=true\" class=\"φcy\" alt=\"image\"></p>\n<p>第一个主成分就是从数据差异性最大（方差最大）的方向提取出来的，第二个主成分则是来自于数据差异性次的方向，并且要与第一个主成分方向正交</p>\n<p><img src=\"https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/数据压缩4.PNG?raw=true\" class=\"φcy\" alt=\"image\"></p>\n<h3 id=\"pca与线性回归的差异\">PCA与线性回归的差异<a href=\"#pca与线性回归的差异\" title=\"PCA与线性回归的差异\"></a></h3><p><img src=\"https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/PCA1.PNG?raw=true\" class=\"φcy\" alt=\"image\"></p>\n<h3 id=\"pca算法流程\">PCA算法流程<a href=\"#pca算法流程\" title=\"PCA算法流程\"></a></h3><ol><li>数据预处理：中心化X - avg（X）</li>\n<li>求样本的协方差矩阵1/m * X *X^T</li>\n<li>对协方差 1/m * X *X^T 矩阵做特征值分解</li>\n<li>选出最大的k个特征值对应的k个特征向量</li>\n<li>将原始数据投影到选取的特征向量上</li>\n<li>输出投影后的数据集</li>\n</ol><h3 id=\"协方差\">协方差<a href=\"#协方差\" title=\"协方差\"></a></h3><p>方差描述一个数据的离散程度：</p>\n<p><img src=\"https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/协方差1.PNG?raw=true\" class=\"φcy\" alt=\"image\"></p>\n<p>协方差描述两个数据的相关性，接近1即是正相关，接近-1即是负相关，接近0即是不相关</p>\n<p><img src=\"https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/协方差2.PNG?raw=true\" class=\"φcy\" alt=\"image\"></p>\n<h3 id=\"协方差矩阵\">协方差矩阵<a href=\"#协方差矩阵\" title=\"协方差矩阵\"></a></h3><p>协方差只能处理二维问题，那维度多了自然需要计算多个协方差，我们可以使用矩阵来组织这些数据。</p>\n<p>协方差矩阵是一个对称的矩阵，而且对角线是各个维度的方差。</p>\n<p>二维：</p>\n<p><img src=\"https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/协方差3.PNG?raw=true\" class=\"φcy\" alt=\"image\"></p>\n<p>三维：</p>\n<p><img src=\"https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/协方差4.PNG?raw=true\" class=\"φcy\" alt=\"image\"></p>\n<p>n个特征，m个样本，n行m列</p>\n<p><img src=\"https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/协方差矩阵1.PNG?raw=true\" class=\"φcy\" alt=\"image\"></p>\n<p>n行m列乘m行n列-&gt; n行n列</p>\n<p><img src=\"https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/协方差矩阵2.PNG?raw=true\" class=\"φcy\" alt=\"image\"></p>\n<p><img src=\"https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/协方差矩阵3.PNG?raw=true\" class=\"φcy\" alt=\"image\"></p>\n<h3 id=\"特征值与特征向量\">特征值与特征向量<a href=\"#特征值与特征向量\" title=\"特征值与特征向量\"></a></h3><p>通过数据集的协方差矩阵及其特征值分析，我们可以得到协方差矩阵的特征向量和特征值。我们需要保留k个维度的特征就选取最大的k个特征值</p>\n","prev":{"title":"聚类","link":"2019/02/17/聚类"},"next":{"title":"SVM","link":"2019/02/10/SVM"},"plink":"http://yoursite.com/2019/02/14/PCA/","toc":[{"id":"主成分分析","title":"主成分分析","index":"1"},{"id":"数据压缩","title":"数据压缩","index":"2"},{"id":"数据可视化","title":"数据可视化","index":"3"},{"id":"降维分析","title":"降维分析","index":"4"},{"id":"pca与线性回归的差异","title":"PCA与线性回归的差异","index":"5"},{"id":"pca算法流程","title":"PCA算法流程","index":"6"},{"id":"协方差","title":"协方差","index":"7"},{"id":"协方差矩阵","title":"协方差矩阵","index":"8"},{"id":"特征值与特征向量","title":"特征值与特征向量","index":"9"}],"copyright":{"link":"<a href=\"http://yoursite.com/2019/02/14/PCA/\" title=\"PCA\">http://yoursite.com/2019/02/14/PCA/</a>","license":"自由转载-非商用-禁止演绎-保持署名 (<a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\" rel=\"external nofollow noopener\" target=\"_blank\">CC BY-NC-ND 4.0</a>)"}}