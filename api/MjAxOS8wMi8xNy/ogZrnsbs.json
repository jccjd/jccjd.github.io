{"title":"聚类","date":"2019-02-16T16:00:00.000Z","link":"2019/02/17/聚类","tags":["Machine Learning"],"categories":["Machine Learning"],"updated":"2019-10-25T08:19:02.503Z","content":"<h3 id=\"聚类\">聚类<a href=\"2019/02/17/聚类#聚类\"></a></h3><p>聚类算法是非监督学习算法，将并没有明确的标签数据中，输入算法中，找到这些数据中</p>\n<p>的内在联系，一个能够找到圈出这些点集，被称为聚类算法</p>\n<p><img src=\"https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/%E8%81%9A%E7%B1%BB1.PNG?raw=true\" alt=\"image\" class=\"article-img\"></p>\n<h3 id=\"K-MEANS\">K-MEANS<a href=\"2019/02/17/聚类#K-MEANS\"></a></h3><pre><code>- 算法接受参数K，然后将事先输入的n个数据\n对象划分为k个聚类以便使得所获得的聚类满足：\n同一聚类中的对象相似度较高，\n而不同聚类中的对象相似度较小\n\n- 算法思想：以空间中k哥点为中心进行聚类，\n对最靠近他们的对象归类。\n通过迭代的方法，逐次更新各聚类中心得值，\n直至得到最好的聚类结果</code></pre><p>具体步骤：</p>\n<pre><code>1. 先从没有标签的元素集合A中随机取K个元素，作为K个子集各自的重心\n2. 分别计算剩下的元素到k个子集重心的距离（这里的距离也可以使用欧式距离）,\n根据距离将这些元素分别划归到最近的子集\n3. 根据聚类结果，重新计算重心（重心的计算方法是计算子集中所以元素各个维度的算术平均值）\n4.将集合A中全部元素按照新的重心然后再重新聚类\n5. 重复第4步， 直到聚类结果不在发生变化</code></pre><p>如下有四个点，假设取（1,1）（2,1）为两个分类的中心点<br><img src=\"https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/%E8%81%9A%E7%B1%BB2.PNG?raw=true\" alt=\"image\"></p>\n<p>然后计算所有的点到中心的距离：</p>\n<p><img src=\"https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/%E8%81%9A%E7%B1%BB3.PNG?raw=true\" alt=\"image\" class=\"article-img\"></p>\n<blockquote>\n<p>第一行是所有点到第一类点的距离，第二行是所有点到第二类点的距离</p>\n</blockquote>\n<p>然后根据距离的大小将四个点进行分类</p>\n<p><img src=\"https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/%E8%81%9A%E7%B1%BB4.PNG?raw=true\" alt=\"image\" class=\"article-img\"></p>\n<blockquote>\n<p>第一行代表第一个类别，第二行代表第二个类别</p>\n</blockquote>\n<p>然后重新计算重心：</p>\n<p>第二个类别C2：</p>\n<p><img src=\"https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/%E8%81%9A%E7%B1%BB5.PNG?raw=true\" alt=\"image\" class=\"article-img\"></p>\n<p>然后重复以上步骤：<br><img src=\"https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/%E8%81%9A%E7%B1%BB6.PNG?raw=true\" alt=\"image\"></p>\n<p>直到聚类不发生变化</p>\n<h3 id=\"Mini-Batch-K-Means\">Mini Batch K-Means<a href=\"2019/02/17/聚类#Mini-Batch-K-Means\"></a></h3><p>Mini Batch K-means算法是k-Means算法的变种，采用小批量的数据子集减少计算时间，这里所谓的小批量是指每次训练算法时所随机抽取的数据子集，</p>\n<p>采用这些随机产生的子集进行训练算法，大大减少了计算时间，结果一般只略差于标准算法。</p>\n<p>该算法的迭代步骤有两步：</p>\n<ol>\n<li>从数据集中随机抽取一些数据形成小批量，把他们分配给最近的质心</li>\n<li>更新质心， 与k均值算法相比，数据的更新是在每一个的样本集上。mini Batch K-Means 比K-means有更快的，收敛速度，<br>但同时也降低了聚类的效果，但是在实际项目中却表现的不明显。</li>\n</ol>\n<h3 id=\"K-MEANS算法分析\">K-MEANS算法分析<a href=\"2019/02/17/聚类#K-MEANS算法分析\"></a></h3><p>k-means算法在有些情况下是会出现问题的：</p>\n<ol>\n<li>对k个初始质心得选择比较敏感，容易陷入局部最小值。例如，我们上面的算法运行的时候，有可能会得到不同的结果，如下面这两种情况。K-means也是收敛了，只是收敛了局部最小值：</li>\n</ol>\n<p><img src=\"https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/kmeans1.PNG?raw=true\" alt=\"image\" class=\"article-img\"></p>\n<p>解决办法：</p>\n<pre><code>使用多次的随机初始化，计算每一次建模得到的代价函数的值，选取代价函数最小结果作为聚类结果\n\nfor i = 1 to 100 {\n    Randomly initialize K-means\n    Run k-means.et\n    Compute cost function(distortion)  </code></pre><p><img src=\"https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/kmeans4.PNG?raw=true\" alt=\"image\" class=\"article-img\"></p>\n<ol start=\"2\">\n<li>k的值选择是用户决定的，不同的k得到的结果会有挺大的不同，如图所示，左边是k = 3 的结果，蓝色的簇太稀疏了，蓝色的簇应该可以在划分成两个簇。右边是k=5的结果，红色和蓝色的簇应该合并成为一个簇</li>\n</ol>\n<p><img src=\"https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/kmeans2.PNG?raw=true\" alt=\"image\" class=\"article-img\"></p>\n<blockquote>\n<p>解决办法：</p>\n</blockquote>\n<pre><code>肘部法则：使用肘部法则来选取k值</code></pre><p><img src=\"https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/%E8%82%98%E9%83%A8%E6%B3%95%E5%88%991.PNG?raw=true\" alt=\"image\" class=\"article-img\"></p>\n<ol start=\"3\">\n<li>存在局限性，如下这种非球状的数据结构分布不适用：</li>\n</ol>\n<p><img src=\"https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/kmeans3.PNG?raw=true\" alt=\"image\" class=\"article-img\"></p>\n<ol start=\"4\">\n<li>数据量比较大的时候，收敛会比较慢</li>\n</ol>\n<h3 id=\"可视化K-MEANS\">可视化K-MEANS<a href=\"2019/02/17/聚类#可视化K-MEANS\"></a></h3><p><a href=\"https://www.naftaliharris.com/blog/visualizing-k-means-clustering\" target=\"_blank\" rel=\"noopener\">https://www.naftaliharris.com/blog/visualizing-k-means-clustering</a></p>\n<h3 id=\"基于密度的方法：DBSCAN\">基于密度的方法：DBSCAN<a href=\"2019/02/17/聚类#基于密度的方法：DBSCAN\"></a></h3><p>DBSCAN = Density-Based Spatial Clustering of Applications with Noise</p>\n<p>该算法将具有足够高密度的区域划分为簇，并可以发现任何形状的聚类</p>\n<p><img src=\"https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/DBSCAN1.PNG?raw=true\" alt=\"image\" class=\"article-img\"></p>\n<p><img src=\"https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/DBSCAN2.PNG?raw=true\" alt=\"image\" class=\"article-img\"></p>\n<p>ε领域：</p>\n<pre><code>给定对象半径ε内的区域称为该对象的ε领域</code></pre><p>核心对象：</p>\n<pre><code>如果给定ε领域内的样本点数大于等于Minpoints,则该对象为核心对象</code></pre><p>直接密度可达：</p>\n<pre><code>直接密度可达：给定一个对象集合D，如果p在q的ε领域内，且q是一个核心对象，\n则我们说对象p从q出发是直接密度可达的（directly density-reachable）</code></pre><p>密度可达：</p>\n<pre><code>集合D，存在一个对象链\np1，p2....pn，p1=q，pn=p,pi+1z是从pi关于ε和Minpoints直接密度可达，\n则称点p是q关于ε和Minpoints密度可达的。</code></pre><p>密度相连：</p>\n<pre><code>集合D存在点o，使得点p，q是从o关于ε和MinPoints密度可达的，那么点p，q是关于ε和Minpoints\n密度相连的。</code></pre><h3 id=\"DBSCAN算法思想\">DBSCAN算法思想<a href=\"2019/02/17/聚类#DBSCAN算法思想\"></a></h3><ol>\n<li>指定合适的ε和Minpoints</li>\n<li>计算所有的样本点，如果点p的ε邻域里有超过Minpoints个点，则创建一个以p为核心点的新簇</li>\n<li>反复寻找那些核心点直接密度可达（之后可能是密度可达）的点，将其加入到相应的簇，对于核心点发生“密度相连”状况的簇，予以合并</li>\n<li>当没有新的点可以被添加到任何簇时，算法结束</li>\n</ol>\n<p>算法缺点：</p>\n<pre><code>- 当数据量增大时，要求较大的内存支持，i/o消耗也很大\n- 当空间聚类的密度不均匀，聚类间距相差很大时，聚类质量较差</code></pre><p>DBSCAN和K-MEANS比较：</p>\n<pre><code>- DBSCAN不需要输入聚类个数\n- 聚类簇的形状没有要求\n- 可以在需要时输入过滤噪声的参数</code></pre>","prev":{"title":"异常检测","link":"2019/02/24/异常检测"},"next":{"title":"PCA","link":"2019/02/14/PCA"},"plink":"http://jccjd.top/2019/02/17/聚类/","copyright":{"link":"<a href=\"http://jccjd.top/2019/02/17/聚类/\" title=\"聚类\">http://jccjd.top/2019/02/17/聚类/</a>","license":"自由转载-非商用-禁止演绎-保持署名 (<a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\" rel=\"external nofollow noopener\" target=\"_blank\">CC BY-NC-ND 4.0</a>)"}}