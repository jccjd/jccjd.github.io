{"title":"决策树","date":"2019-08-18T16:00:00.000Z","date_formatted":{"ll":"Aug 19, 2019","L":"08/19/2019","MM-DD":"08-19"},"link":"2019/08/19/决策树","tags":["Machine Learning"],"categories":["Machine Learning"],"updated":"2020-02-09T08:37:53.000Z","content":"<h3 id=\"决策树\">决策树<a href=\"#决策树\" title=\"决策树\"></a></h3><p>决策树见名知意可以知道这是一个用来进行决策的东西</p>\n<h3 id=\"信息熵\">信息熵<a href=\"#信息熵\" title=\"信息熵\"></a></h3><p>用来表示集合的数据的纯度</p>\n<h3 id=\"信息增益\">信息增益<a href=\"#信息增益\" title=\"信息增益\"></a></h3><p>当依据某个特征对数据集进行划分时产生的子集，这时对子集求信息熵，和原始熵的差值，这个值越大越好在决策树的划分中要知道很多的数据，要知道类别，<br>知道正例反例，需要很多的信息才能描绘出一颗决策树</p>\n<p>在决定每次要用哪个特征划分的时候，要将当前全都的信息增益求出得到最大增益，用该特征对数据进行划分，当然这是在ID3算法中的策略</p>\n<h3 id=\"增益率\">增益率<a href=\"#增益率\" title=\"增益率\"></a></h3><p>当通过某个特征划分的子集过于细致，那么信息增益会是当前特征中的最优，但这并不具有泛化性，使用增益率可以解决这个问题当划分的子集越多，增益率<br>越小。但是显然增益率是偏爱于划分出子集少的特征，</p>\n<h3 id=\"基尼指数\">基尼指数<a href=\"#基尼指数\" title=\"基尼指数\"></a></h3><p>CART(classification and Regression Tree)使用基尼值来作为数据集纯度的度量,其思想是在分类出的样本中随机选出的两个样本不一样的概率，所以<br>这个概率越小分类出的子集就越纯</p>\n","prev":{"title":"Python实现循环双链表","link":"2019/08/26/双链表"},"next":{"title":"Python实现单链表","link":"2019/08/10/Python实现单链表"},"plink":"http://yoursite.com/2019/08/19/决策树/","toc":[{"id":"决策树","title":"决策树","index":"1"},{"id":"信息熵","title":"信息熵","index":"2"},{"id":"信息增益","title":"信息增益","index":"3"},{"id":"增益率","title":"增益率","index":"4"},{"id":"基尼指数","title":"基尼指数","index":"5"}]}