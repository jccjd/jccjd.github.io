{"title":"learn_note_06","date":"2020-06-18T11:08:05.125Z","date_formatted":{"ll":"Jun 18, 2020","L":"06/18/2020","MM-DD":"06-18"},"link":"2020/06/18/learn_note_06","tags":["daily_work"],"categories":["Machine Learning"],"updated":"2020-06-18T11:08:05.125Z","content":"<h3 id=\"安装cuda\">安装cuda<a href=\"#安装cuda\" title=\"安装cuda\"></a></h3><p>Ubuntu 20.04 下使用 <code>pytorch</code>GPU版</p>\n<ol><li><p>下载Linux对应的驱动，查看本机显卡能够配置的驱动信息，recommended为推荐安装</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ubuntu-drivers devices</span><br><span class=\"line\"><span class=\"comment\"># vendor   : NVIDIA Corporation</span></span><br><span class=\"line\"><span class=\"comment\"># model    : GP107 [GeForce GTX 1050 Ti]</span></span><br><span class=\"line\"><span class=\"comment\"># driver   : nvidia-driver-435 - distro non-free</span></span><br><span class=\"line\"><span class=\"comment\"># driver   : nvidia-driver-390 - distro non-free</span></span><br><span class=\"line\"><span class=\"comment\"># driver   : nvidia-driver-440 - distro non-free recommended</span></span><br><span class=\"line\"><span class=\"comment\"># driver   : xserver-xorg-video-nouveau - distro free builtin</span></span><br></pre></td></tr></table></figure></li>\n<li><p>下载cuda, Ubuntu 20.04 可以用Ubuntu18.04的版本</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget http://developer.download.nvidia.com/compute/cuda/11.0.1/local_installers/cuda_11.0.1_450.36.06_linux.run</span><br></pre></td></tr></table></figure></li>\n<li><p>gcc降级</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apt-get install gcc-7 g++-7</span><br><span class=\"line\"><span class=\"comment\"># 切换版本</span></span><br><span class=\"line\">sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-7 100</span><br><span class=\"line\">sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-9 50</span><br></pre></td></tr></table></figure></li>\n</ol><ol><li><p>安装<br> cuda安装包里有显卡驱动，之前安装过了，有一项driver要去掉</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo sh cuda_11.0.1_450.36.06_linux.run</span><br></pre></td></tr></table></figure></li>\n<li><p>配置环境变量, 在<code>~/.bashrc</code>下最后一行添加</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># cuda-version=9.0, 10.0, 11.0 填自己的cuda-version</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"string\">\"/usr/local/cuda-version/bin:<span class=\"variable\">$PATH</span>\"</span> </span><br><span class=\"line\"><span class=\"built_in\">export</span> LD_LIBRARY_PATH=<span class=\"string\">\"/usr/local/cuda-version/lib64:<span class=\"variable\">$LD_LIBRARY_PATH</span>\"</span></span><br></pre></td></tr></table></figure></li>\n<li><p>检验</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nvcc -V</span><br></pre></td></tr></table></figure></li>\n</ol><h3 id=\"根据xml分割图像\">根据xml分割图像<a href=\"#根据xml分割图像\" title=\"根据xml分割图像\"></a></h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> xml.etree.ElementTree <span class=\"keyword\">as</span> ET</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">wd = os.getcwd()</span><br><span class=\"line\">data_dir = os.path.join(wd, <span class=\"string\">'train/'</span>)</span><br><span class=\"line\">data_content_list = os.listdir(data_dir)</span><br><span class=\"line\">xmls_name = [i.split(<span class=\"string\">'.'</span>)[<span class=\"number\">0</span>] <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> data_content_list <span class=\"keyword\">if</span> i.endswith(<span class=\"string\">\".xml\"</span>)]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> xmlname <span class=\"keyword\">in</span> xmls_name:</span><br><span class=\"line\">    tree = ET.parse(data_dir + xmlname + <span class=\"string\">'.xml'</span>)</span><br><span class=\"line\">    root = tree.getroot()</span><br><span class=\"line\"></span><br><span class=\"line\">    image_count = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> obj <span class=\"keyword\">in</span> root.iter(<span class=\"string\">'object'</span>):</span><br><span class=\"line\">        image_label = obj.find(<span class=\"string\">'name'</span>).text</span><br><span class=\"line\">        bndbox = obj.find(<span class=\"string\">'bndbox'</span>)</span><br><span class=\"line\">        image_box = [int(bndbox.find(<span class=\"string\">'xmin'</span>).text), int(bndbox.find(<span class=\"string\">'xmax'</span>).text), int(bndbox.find(<span class=\"string\">'ymin'</span>).text), int(bndbox.find(<span class=\"string\">'ymax'</span>).text)]</span><br><span class=\"line\">        img = cv2.imread( data_dir + xmlname+<span class=\"string\">'.AIpng'</span>)</span><br><span class=\"line\">        y0 = image_box[<span class=\"number\">0</span>]</span><br><span class=\"line\">        y1 = image_box[<span class=\"number\">1</span>]</span><br><span class=\"line\">        x0 = image_box[<span class=\"number\">2</span>]</span><br><span class=\"line\">        x1 = image_box[<span class=\"number\">3</span>]</span><br><span class=\"line\">        <span class=\"comment\"># 直接裁剪</span></span><br><span class=\"line\">        cropped = img[x0:x1, y0:y1]  <span class=\"comment\"># 裁剪坐标为[y0:y1, x0:x1]</span></span><br><span class=\"line\">        newname = xmlname + str(image_count) + <span class=\"string\">'.png'</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> image_label == <span class=\"string\">'normal'</span>:</span><br><span class=\"line\">            cv2.imwrite(wd+<span class=\"string\">'/mydata/nml/'</span>+ newname, cropped)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            cv2.imwrite(wd+<span class=\"string\">'/mydata/dic/'</span>+ newname, cropped)</span><br><span class=\"line\">        image_count += <span class=\"number\">1</span></span><br><span class=\"line\">    print(xmlname +<span class=\"string\">\"images--&gt;\"</span>+ str(image_count))</span><br></pre></td></tr></table></figure><h3 id=\"tmux\">tmux<a href=\"#tmux\" title=\"tmux\"></a></h3><div class=\"φcz\"><div class=\"φdb\"><table><thead><tr>\n<th align=\"center\"><code>ctrl-b</code> + <code>&quot;</code></th><th align=\"center\">当前面板上下一分为二，下侧新建面板(C-b 按后等1秒)</th></tr>\n</thead><tbody><tr>\n<td align=\"center\"><code>ctrl-b</code> + <code>%</code></td><td align=\"center\">当前面板上下一分为二，下侧新建面板(C-b 按后等1秒)</td></tr>\n<tr>\n<td align=\"center\"></td><td align=\"center\"></td></tr>\n</tbody></table></div></div><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tmux new -s demo <span class=\"comment\"># 新建窗口 tmux 默认为0号</span></span><br><span class=\"line\">tmux a -t demo <span class=\"comment\"># 进入</span></span><br><span class=\"line\">vi ~/.tmux.conf 启用鼠标</span><br><span class=\"line\"><span class=\"built_in\">set</span>-option -g mouse on</span><br></pre></td></tr></table></figure><h3 id=\"restnet跑数据\">restNet跑数据<a href=\"#restnet跑数据\" title=\"restNet跑数据\"></a></h3><ol><li><p>跑出的模型如何去保存</p>\n<p>在每轮训练的时候，定义一个<code>bast_acc</code>，当测试集的准确度大于这个值的时候就进行保存</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bast_acc = <span class=\"number\">0.0</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> rang(num_epoch):</span><br><span class=\"line\">    .....</span><br><span class=\"line\">    epoch_acc = runing_corrects/data_size</span><br><span class=\"line\">    ....</span><br><span class=\"line\">    <span class=\"keyword\">if</span> epoch_acc &gt; bast_acc:</span><br><span class=\"line\">        bast_acc = eporch_acc</span><br><span class=\"line\">        torch.save(model, <span class=\"string\">'model_name.pt'</span>)</span><br></pre></td></tr></table></figure></li>\n</ol><h3 id=\"用跑好的模型分辨图片\">用跑好的模型分辨图片<a href=\"#用跑好的模型分辨图片\" title=\"用跑好的模型分辨图片\"></a></h3><ol><li><p>将目标文件夹下的数据全部读取</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">get_dir_all_file</span><span class=\"params\">(dir, Filelist)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">    dir： 目标文件夹</span></span><br><span class=\"line\"><span class=\"string\">    Filelist: 传入[], 便于递归</span></span><br><span class=\"line\"><span class=\"string\">    return: 文件夹下的所有文件</span></span><br><span class=\"line\"><span class=\"string\">    '''</span></span><br><span class=\"line\">    newDir = dir</span><br><span class=\"line\">    <span class=\"keyword\">if</span> os.path.isfile(dir):</span><br><span class=\"line\">        Filelist.append(dir)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> os.path.isdir(dir):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> s <span class=\"keyword\">in</span> os.listdir(dir):</span><br><span class=\"line\">            newDir = os.path.join(dir, s)</span><br><span class=\"line\">            get_dir_all_file(newDir, Filelist)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Filelist</span><br></pre></td></tr></table></figure></li>\n<li><p>图片读取</p>\n<p>图片读取遇到问题</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">RuntimeError: Expected <span class=\"number\">4</span>-dimensional input <span class=\"keyword\">for</span> <span class=\"number\">4</span>-dimensional weight [<span class=\"number\">64</span>, <span class=\"number\">3</span>, <span class=\"number\">7</span>, <span class=\"number\">7</span>], but got <span class=\"number\">3</span>-dimensional input of size [<span class=\"number\">3</span>, <span class=\"number\">224</span>, <span class=\"number\">224</span>] instead</span><br></pre></td></tr></table></figure><p>主要是通道问题，传入tensor的维度不对</p>\n<p>参考：<a href=\"https://blog.csdn.net/weixin_38208741/article/details/97894292\" target=\"_blank\">https://blog.csdn.net/weixin_38208741/article/details/97894292</a></p>\n<p>​        </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">image_to_image_tensor</span><span class=\"params\">(image_path)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    image_path: 传入的图片地址</span></span><br><span class=\"line\"><span class=\"string\">    return: 直接可传入网络的tesnor</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    device = torch.device(<span class=\"string\">\"cuda:0\"</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">\"cpu\"</span>)</span><br><span class=\"line\">    image_PIL = Image.open(image_path)</span><br><span class=\"line\"></span><br><span class=\"line\">    preprocess_transform = transforms.Compose([</span><br><span class=\"line\">        transforms.Resize((<span class=\"number\">224</span>, <span class=\"number\">224</span>)),</span><br><span class=\"line\">        transforms.ToTensor(),</span><br><span class=\"line\">    ])</span><br><span class=\"line\">    image_tensor = preprocess_transform(image_PIL)</span><br><span class=\"line\">    image_tensor.unsqueeze_(<span class=\"number\">0</span>)</span><br><span class=\"line\">    image_tensor = image_tensor.to(device)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> image_tensor</span><br></pre></td></tr></table></figure></li>\n<li><p>model读取直接load()</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">model = torch.load(model_path)</span><br><span class=\"line\">model.eval()</span><br><span class=\"line\">out = model(image_tensor) <span class=\"comment\"># out 为每个类别的概率</span></span><br></pre></td></tr></table></figure></li>\n</ol><h3 id=\"20200617\">20200617<a href=\"#20200617\" title=\"20200617\"></a></h3><ul><li><p>训练数据时对图片的处理进行了左右对调，图片中染色体，其实是分不清楚上下的，因此在训练集中要随机对图片进行左右和上下翻转</p>\n<p>对上下，左右都翻转的准确率是93-94，</p>\n</li>\n<li><p>输入的数据集中其实染色体的左右和上下就是随机的，应该不需要在对图片进行翻转操作</p>\n<p>不进行旋转的准确率有95-96</p>\n</li>\n</ul><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data_transforms = &#123;</span><br><span class=\"line\">    <span class=\"string\">'train'</span>: transforms.Compose([</span><br><span class=\"line\">        <span class=\"comment\"># 随机在图像上裁剪出224*224大小的图像</span></span><br><span class=\"line\">        <span class=\"comment\">#transforms.RandomResizedCrop(224),</span></span><br><span class=\"line\">        transforms.Resize((<span class=\"number\">224</span>, <span class=\"number\">224</span>)),</span><br><span class=\"line\">        <span class=\"comment\"># transforms.CenterCrop(224),</span></span><br><span class=\"line\">        <span class=\"comment\"># 将图像随机翻转,</span></span><br><span class=\"line\">        transforms.RandomHorizontalFlip(),</span><br><span class=\"line\">        <span class=\"comment\"># 将图像数据,转换为网络训练所需的tensor向量</span></span><br><span class=\"line\">        transforms.ToTensor(),</span><br><span class=\"line\">        <span class=\"comment\"># 图像归一化处理</span></span><br><span class=\"line\">        <span class=\"comment\"># 个人理解,前面是3个通道的均值,后面是3个通道的方差</span></span><br><span class=\"line\">        <span class=\"comment\"># transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])</span></span><br><span class=\"line\">    ]),</span><br><span class=\"line\">    <span class=\"string\">'val'</span>: transforms.Compose([</span><br><span class=\"line\">        transforms.Resize((<span class=\"number\">224</span>, <span class=\"number\">224</span>)),</span><br><span class=\"line\">        <span class=\"comment\"># transforms.CenterCrop(224),</span></span><br><span class=\"line\">        transforms.ToTensor(),</span><br><span class=\"line\">        <span class=\"comment\"># transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])</span></span><br><span class=\"line\">    ]),</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><h3 id=\"numpy-list-tensor-相互转换\"><code>numpy</code> <code>list</code> <code>tensor</code> 相互转换<a href=\"#numpy-list-tensor-相互转换\" title=\"numpy list tensor 相互转换\"></a></h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">list = [<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>]</span><br><span class=\"line\">narray = np.array(list)</span><br><span class=\"line\">tensor = torch.tensor(narray) <span class=\"comment\"># or torch.from_numpy(narray)</span></span><br><span class=\"line\">tensor = torch.tensor(list)</span><br><span class=\"line\"></span><br><span class=\"line\">narray = tensor.numpy()</span><br><span class=\"line\">list = narray.tolist()</span><br><span class=\"line\">list = tensor.numpy().tolist()</span><br></pre></td></tr></table></figure><h3 id=\"tensor-和tensor\"><code>tensor</code> 和<code>Tensor</code><a href=\"#tensor-和tensor\" title=\"tensor 和Tensor\"></a></h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.tensor([<span class=\"number\">3</span>, <span class=\"number\">4</span>]) <span class=\"comment\"># 接收实际的数据</span></span><br><span class=\"line\">torch.Tensor(<span class=\"number\">3</span>, <span class=\"number\">4</span>) <span class=\"comment\"># 接收维度生成数据</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a = torch.tensor([<span class=\"number\">3</span>, <span class=\"number\">4</span>])</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a</span><br><span class=\"line\">tensor([<span class=\"number\">3</span>, <span class=\"number\">4</span>])</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>b = torch.Tensor(<span class=\"number\">3</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>b</span><br><span class=\"line\">tensor([[ <span class=\"number\">4.9727e-37</span>,  <span class=\"number\">0.0000e+00</span>,  <span class=\"number\">0.0000e+00</span>,  <span class=\"number\">9.9577e-06</span>],</span><br><span class=\"line\">        [ <span class=\"number\">0.0000e+00</span>,  <span class=\"number\">5.3334e-05</span>,  <span class=\"number\">0.0000e+00</span>,  <span class=\"number\">5.4408e-05</span>],</span><br><span class=\"line\">        [<span class=\"number\">-2.0000e+00</span>,  <span class=\"number\">2.7888e+03</span>,  <span class=\"number\">1.0842e-19</span>,  <span class=\"number\">1.3884e+03</span>]])</span><br></pre></td></tr></table></figure><h3 id=\"tensor-维度变换\">tensor 维度变换<a href=\"#tensor-维度变换\" title=\"tensor 维度变换\"></a></h3><ol><li><p>View/reshape</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># view和reshape是相同的</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a = torch.rand(<span class=\"number\">4</span>, <span class=\"number\">1</span>, <span class=\"number\">28</span>, <span class=\"number\">28</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a.shape</span><br><span class=\"line\">torch.Size([<span class=\"number\">4</span>, <span class=\"number\">1</span>, <span class=\"number\">28</span>, <span class=\"number\">28</span>])</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a.view(<span class=\"number\">4</span>, <span class=\"number\">28</span>*<span class=\"number\">28</span>)</span><br><span class=\"line\">tensor([[<span class=\"number\">0.8865</span>, <span class=\"number\">0.7460</span>, <span class=\"number\">0.6992</span>,  ..., <span class=\"number\">0.7661</span>, <span class=\"number\">0.6923</span>, <span class=\"number\">0.3467</span>],</span><br><span class=\"line\">        [<span class=\"number\">0.3727</span>, <span class=\"number\">0.7315</span>, <span class=\"number\">0.2028</span>,  ..., <span class=\"number\">0.7744</span>, <span class=\"number\">0.6415</span>, <span class=\"number\">0.7241</span>],</span><br><span class=\"line\">        [<span class=\"number\">0.1010</span>, <span class=\"number\">0.5918</span>, <span class=\"number\">0.7292</span>,  ..., <span class=\"number\">0.2669</span>, <span class=\"number\">0.5328</span>, <span class=\"number\">0.6228</span>],</span><br><span class=\"line\">        [<span class=\"number\">0.9942</span>, <span class=\"number\">0.7522</span>, <span class=\"number\">0.7621</span>,  ..., <span class=\"number\">0.1876</span>, <span class=\"number\">0.6260</span>, <span class=\"number\">0.3402</span>]])</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a.view(<span class=\"number\">4</span>, <span class=\"number\">28</span>*<span class=\"number\">28</span>).shape</span><br><span class=\"line\">torch.Size([<span class=\"number\">4</span>, <span class=\"number\">784</span>])</span><br><span class=\"line\">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></li>\n</ol><ol><li><p>Squeeze/unsqueeze</p>\n<p>删减维度增加维度， Squeeze 和unsqueeze类似，但如果不传入索引，Squeeze会将能挤压的维度都挤压掉</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a.shape</span><br><span class=\"line\">torch.Size([<span class=\"number\">4</span>, <span class=\"number\">1</span>, <span class=\"number\">28</span>, <span class=\"number\">28</span>])</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a.unsqueeze(<span class=\"number\">0</span>).shape <span class=\"comment\"># 0为索引</span></span><br><span class=\"line\">torch.Size([<span class=\"number\">1</span>, <span class=\"number\">4</span>, <span class=\"number\">1</span>, <span class=\"number\">28</span>, <span class=\"number\">28</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>b = torch.tensor([<span class=\"number\">1.2</span>, <span class=\"number\">2.3</span>])</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>b.unsqueeze(<span class=\"number\">-1</span>)</span><br><span class=\"line\">tensor([[<span class=\"number\">1.2000</span>],</span><br><span class=\"line\">        [<span class=\"number\">2.3000</span>]])</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>b.unsqueeze(<span class=\"number\">0</span>)</span><br><span class=\"line\">tensor([[<span class=\"number\">1.2000</span>, <span class=\"number\">2.3000</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># example 对b进行扩张加到f上</span></span><br><span class=\"line\">b = torch.rand(<span class=\"number\">32</span>)</span><br><span class=\"line\">f = torch.rand(<span class=\"number\">4</span>, <span class=\"number\">32</span>, <span class=\"number\">14</span>, <span class=\"number\">14</span>) </span><br><span class=\"line\"></span><br><span class=\"line\">torch.Size([<span class=\"number\">1</span>, <span class=\"number\">32</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>])</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>b = torch.rand(<span class=\"number\">32</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>b = b.unsqueeze(<span class=\"number\">1</span>).unsqueeze(<span class=\"number\">2</span>).unsqueeze(<span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>b.shape</span><br><span class=\"line\">torch.Size([<span class=\"number\">1</span>, <span class=\"number\">32</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>])</span><br></pre></td></tr></table></figure></li>\n</ol><ol><li><p>Transpose/t/permute</p>\n<p>矩阵转置</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a = torch.randn(<span class=\"number\">3</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\">a.t() <span class=\"comment\"># t 只限二维</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">### transpose</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a = torch.rand(<span class=\"number\">4</span>, <span class=\"number\">3</span>, <span class=\"number\">32</span>, <span class=\"number\">32</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a1 = a.transpose(<span class=\"number\">1</span>, <span class=\"number\">3</span>).view(<span class=\"number\">4</span>, <span class=\"number\">3</span> * <span class=\"number\">32</span> * <span class=\"number\">32</span>).view(<span class=\"number\">4</span>, <span class=\"number\">3</span>, <span class=\"number\">32</span>, <span class=\"number\">32</span>) <span class=\"comment\"># 数据不连续，使用contiguous</span></span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"&lt;stdin&gt;\"</span>, line <span class=\"number\">1</span>, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">RuntimeError: view size <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> compatible <span class=\"keyword\">with</span> input tenso<span class=\"string\">r's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.</span></span><br><span class=\"line\"><span class=\"string\">&gt;&gt;&gt; a1 = a.transpose(1, 3).contiguous().view(4, 3 * 32 * 32).view(4, 3, 32, 32)</span></span><br><span class=\"line\"><span class=\"string\">&gt;&gt;&gt; a2 = a.transpose(1, 3).contiguous().view(4, 3 * 32 * 32).view(4, 3, 32, 32).transpose(1,3)</span></span><br><span class=\"line\"><span class=\"string\">&gt;&gt;&gt; a1.shape, a2.shape</span></span><br><span class=\"line\"><span class=\"string\">(torch.Size([4, 3, 32, 32]), torch.Size([4, 32, 32, 3]))</span></span><br><span class=\"line\"><span class=\"string\">&gt;&gt;&gt; a2 = a.transpose(1, 3).contiguous().view(4, 3 * 32 * 32).view(4,32</span></span><br><span class=\"line\"><span class=\"string\">, 32,3).transpose(1,3)</span></span><br><span class=\"line\"><span class=\"string\">&gt;&gt;&gt; a1.shape, a2.shape</span></span><br><span class=\"line\"><span class=\"string\">(torch.Size([4, 3, 32, 32]), torch.Size([4, 3, 32, 32]))</span></span><br><span class=\"line\"><span class=\"string\">&gt;&gt;&gt; torch.all(torch.eq(a, a1))</span></span><br><span class=\"line\"><span class=\"string\">tensor(False)</span></span><br><span class=\"line\"><span class=\"string\">&gt;&gt;&gt; torch.all(torch.eq(a, a2))</span></span><br><span class=\"line\"><span class=\"string\">tensor(True)</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">### permute 维度交换更加简单</span></span><br><span class=\"line\"><span class=\"string\">&gt;&gt;&gt; a.shape</span></span><br><span class=\"line\"><span class=\"string\">torch.Size([4, 3, 32, 32])</span></span><br><span class=\"line\"><span class=\"string\">&gt;&gt;&gt; a.permute(0,2,3,1).shape</span></span><br><span class=\"line\"><span class=\"string\">torch.Size([4, 32, 32, 3])</span></span><br><span class=\"line\"><span class=\"string\">&gt;&gt;&gt;</span></span><br></pre></td></tr></table></figure></li>\n</ol><ol><li><p>Expand/repeat</p>\n<p>给每个维度扩展，将每个维度上的数增大， repeat 会复制数据不建议使用</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>a = torch.rand(<span class=\"number\">4</span>, <span class=\"number\">32</span>, <span class=\"number\">14</span>, <span class=\"number\">14</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>b.shape</span><br><span class=\"line\">torch.Size([<span class=\"number\">1</span>, <span class=\"number\">32</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>])</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>b.expand(<span class=\"number\">4</span>, <span class=\"number\">32</span>, <span class=\"number\">14</span>, <span class=\"number\">14</span>).shape <span class=\"comment\"># 只扩张1的维度，对非1的如果更改会报错</span></span><br><span class=\"line\">torch.Size([<span class=\"number\">4</span>, <span class=\"number\">32</span>, <span class=\"number\">14</span>, <span class=\"number\">14</span>])</span><br><span class=\"line\">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></li>\n</ol><h2 id=\"20200618\">20200618<a href=\"#20200618\" title=\"20200618\"></a></h2><h3 id=\"torch\">torch<a href=\"#torch\" title=\"torch\"></a></h3><ol><li><code>tensor.topk()</code>取指定dim中值最大的索引，比如得到了四张图片是数字0-9的概率列表(4, 10)，可以直接去取概率最大的值是多少。指定k就是取概率最大的前k个</li>\n</ol><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>prob = torch.randn(<span class=\"number\">4</span>,<span class=\"number\">10</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>index = prob.topk(dim=<span class=\"number\">1</span>, k=<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>index</span><br><span class=\"line\">torch.return_types.topk(</span><br><span class=\"line\">values=tensor([[<span class=\"number\">1.2063</span>],</span><br><span class=\"line\">        [<span class=\"number\">0.9129</span>],</span><br><span class=\"line\">        [<span class=\"number\">2.4822</span>],</span><br><span class=\"line\">        [<span class=\"number\">0.4884</span>]]),</span><br><span class=\"line\">indices=tensor([[<span class=\"number\">9</span>],</span><br><span class=\"line\">        [<span class=\"number\">0</span>],</span><br><span class=\"line\">        [<span class=\"number\">3</span>],</span><br><span class=\"line\">        [<span class=\"number\">1</span>]]))</span><br><span class=\"line\">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure><ol><li><p>torch自动求导</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">4</span>]: <span class=\"keyword\">from</span> torch.nn <span class=\"keyword\">import</span> functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"></span><br><span class=\"line\">In [<span class=\"number\">5</span>]: x = torch.ones(<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">In [<span class=\"number\">6</span>]: w = torch.full([<span class=\"number\">1</span>],<span class=\"number\">2</span>)</span><br><span class=\"line\">In [<span class=\"number\">7</span>]: mse = F.mse_loss(torch.ones(<span class=\"number\">1</span>), x * w)</span><br><span class=\"line\">In [<span class=\"number\">8</span>]: torch.autograd.grad(mse,[w]) <span class=\"comment\"># 在自动求导的时候要对求导的项指定 w.requires_grad_()或者在开始的时候指定requires_grad=True,</span></span><br><span class=\"line\">---------------------------------------------------------------------------</span><br><span class=\"line\">RuntimeError                              Traceback (most recent call last)</span><br><span class=\"line\">&lt;ipython-input<span class=\"number\">-8</span><span class=\"number\">-8</span>ffc13237761&gt; <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">----&gt; 1 torch.autograd.grad(mse,[w])</span><br><span class=\"line\">In [<span class=\"number\">9</span>]: w.requires_grad_() <span class=\"comment\"># 在指定后要更新计算图，</span></span><br><span class=\"line\">    </span><br><span class=\"line\">Out[<span class=\"number\">9</span>]: tensor([<span class=\"number\">2.</span>], requires_grad=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure></li>\n</ol><h3 id=\"训练\">训练<a href=\"#训练\" title=\"训练\"></a></h3><ul><li>使用<code>Finetune_with_different_lr.py</code>训练</li>\n<li><code>../data/data_lechen_rotate_50_224_0</code>下的数据，</li>\n<li>模型加载的是<code>backup/my_model_different_lr.pt</code>,</li>\n<li>训练轮数 到了146</li>\n<li>训练的 val Loss 在 93 -91之间徘徊</li>\n</ul><p>猜测原因可能是加载的模型问题，之前的加载的模型文件删除，然后在backup下找的默认模型</p>\n<p>模型加载到GPU训练，问题：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  File <span class=\"string\">\"/home/mmv2/PycharmProjects/ml_venv/lib/python3.8/site-packages/torch/serialization.py\"</span>, line <span class=\"number\">181</span>, <span class=\"keyword\">in</span> default_restore_location</span><br><span class=\"line\">    <span class=\"keyword\">raise</span> RuntimeError(<span class=\"string\">\"don't know how to restore data location of \"</span></span><br><span class=\"line\">RuntimeError: don<span class=\"string\">'t know how to restore data location of torch.FloatStorage (tagged with gpu)</span></span><br></pre></td></tr></table></figure><p>参考：<a href=\"https://blog.csdn.net/bc521bc/article/details/85623515\" target=\"_blank\">https://blog.csdn.net/bc521bc/article/details/85623515</a></p>\n<ul><li><p>使用<code>Finetune_with_different_lr.py</code>训练</p>\n</li>\n<li><p><code>../data/data_lechen_rotate_50_224_0</code>下的数据，</p>\n</li>\n<li><p>模型加载的是<code>backup/model_different_lr_resnet50_lechen_rotate_1730.pt</code></p>\n<blockquote>\n<p>这个在训练 val Loss 在95左右，训练轮数在20轮</p>\n</blockquote>\n</li>\n</ul><p>2.</p>\n<ul><li><p>使用<code>data_lechen_ace_nomal_800</code>数据集训练</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data/data_lechen_ace_normal_800</span><br><span class=\"line\">├── train</span><br><span class=\"line\">│   ├── ace</span><br><span class=\"line\">│   └── normal</span><br><span class=\"line\">└── val</span><br><span class=\"line\">    ├── ace</span><br><span class=\"line\">    └── normal</span><br></pre></td></tr></table></figure></li>\n<li><p>载入模型<code>backup/data_lechen_ace_normal_800_model_different_lr_resnet50_lechen_rotate_130.pt</code></p>\n</li>\n<li><p>训练网络代码<code>Finetune_with_different_lr.py</code></p>\n<blockquote>\n<p>准确率有99，98很高</p>\n</blockquote>\n</li>\n</ul>","next":{"title":"yolov3 doc","link":"2020/06/11/yolov3 doc"},"plink":"http://yoursite.com/2020/06/18/learn_note_06/","toc":[{"id":"安装cuda","title":"安装cuda","index":"1"},{"id":"根据xml分割图像","title":"根据xml分割图像","index":"2"},{"id":"tmux","title":"tmux","index":"3"},{"id":"restnet跑数据","title":"restNet跑数据","index":"4"},{"id":"用跑好的模型分辨图片","title":"用跑好的模型分辨图片","index":"5"},{"id":"20200617","title":"20200617","index":"6"},{"id":"numpy-list-tensor-相互转换","title":"numpy list tensor 相互转换","index":"7"},{"id":"tensor-和tensor","title":"tensor 和Tensor","index":"8"},{"id":"tensor-维度变换","title":"tensor 维度变换","index":"9"}],"copyright":{"link":"<a href=\"http://yoursite.com/2020/06/18/learn_note_06/\" title=\"learn_note_06\">http://yoursite.com/2020/06/18/learn_note_06/</a>","license":"自由转载-非商用-禁止演绎-保持署名 (<a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\" rel=\"external nofollow noopener\" target=\"_blank\">CC BY-NC-ND 4.0</a>)"}}